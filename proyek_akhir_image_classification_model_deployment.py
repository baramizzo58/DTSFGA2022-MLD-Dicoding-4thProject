# -*- coding: utf-8 -*-
"""Proyek Akhir : Image Classification Model Deployment r.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15AKLnJVeygUqWPed8ldy6qTkWTOf-ozU
"""

# Nama lengkap: Noor Kharismawan Akbar
# Username: noor_kharismawan_akbar_nOkP
# No. Telepon: +6281227223150

#import os & pathlib
import os, pathlib

# Memastikan TensorFlow diatas 2.0
import tensorflow as tf
print(tf.__version__)

#To download google drive file
!gdown 14FwvTTzGirdZKRau9sgN43bKABD85iHz

#Install kaggle
!pip install kaggle

#Membuat direktori kaggle
!mkdir ~/.kaggle

#Copy json ke folder kaggle
!cp kaggle.json ~/.kaggle/

#Memberi permission ke file json
!chmod 600 ~/.kaggle/kaggle.json

#Download dataset
!kaggle datasets download hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images

#Unzip dataset
!unzip shoe-vs-sandal-vs-boot-dataset-15k-images.zip

base_dir = "/content/Shoe vs Sandal vs Boot Dataset"

os.listdir(base_dir)

# Pre-processing data dengan image augmentation sesuai kriteria
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Menggunakan image data generator sesuai kriteria
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.2,
    fill_mode='nearest',
    validation_split=0.2)

val_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2)

#input height, weight
height = 102
width = 136

# Mempersiapkan data latih yang akan dipelajari oleh model
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(height,width),
    shuffle=True,
    subset='training')

validation_generator = val_datagen.flow_from_directory(
    base_dir,
    target_size=(height,width),
    subset='validation')

# Menggunakan model sequential sesuai kriteria
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(height, width, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

# Compile model dengan 'adam' optimizer loss function 'categorical_crossentropy'
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

# Menggunakan callback untuk mengstop ketika sudah > 92% sesuai penilaian bintang 5
accuracy_threshold = 92e-2
class my_callbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs = None):
        if logs.get('val_accuracy') > accuracy_threshold:
            print('Reached 92%, stop epoch')
            self.model.stop_training = True

# Latih model dengan model.fit
history = model.fit(
    train_generator,
    steps_per_epoch=25, #berapa batch yang dieksekusi di setiap epoch
    epochs=20, #tambahkan epochs jika akurasi model belum optimal
    validation_data=validation_generator, #menampilkan akurasi pengujian data validasi
    validation_steps=5, #berapa batch yang dieksekusi pada setiap epoch
    verbose=2,
    callbacks = [my_callbacks()])

# Menguji model yg telah dibuat menggunakan gambar yang belum dikenali
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)
 
# Convert SavedModel menjadi .tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
 
tflite_model_file = pathlib.Path('shoesandalboot.tflite')
tflite_model_file.write_bytes(tflite_model)